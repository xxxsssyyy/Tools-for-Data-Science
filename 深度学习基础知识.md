## 深度学习基础知识

### 一.网络训练

* 任务:给定$n$个观测数据$\{x_k\}$，训练网络的各层结点之间的连接权重$w_{ij}$(含偏置项)

* 训练:相继加入训练样本，**并按预定规则调整网络各权重**。

#### 1.有监督训练

希望训练这样一个网络，对每个训练数据，通过该网络计算之后能尽可能输出其原先给定的值。

#### 2.无监督训练

无监督的训练不要求有目标向量，其目的是训练一个网络，使其产生的输出具有某种可理解的规律性。

#### 3.Hebb训练方法（经验方法）

**基本思路**(突触修正假设):如果两个相互联接的处理单元(结点)处于相同的激励电平(即输出值具有 相同的符号)，则突触传导增强(权重增强)。

**训练策略**：数学上，两结点$i$和$j$的连接权重将按它们的输出值之积来改变:

$$w_{ij}^{t+1}=w_{ij}^{t}+\eta y_iz_j$$，其中$\eta$是训练速率，$$y_i,z_j$$是结点$i$和$j$的输出。

#### 4.$\delta$训练方法（分析方法）

**基本思路**:按差值$\delta$(值)最小准则连续地修正各连接权重的强度。

差值最小:是指处理单元所要求的输出与当前实际输出间的差值，通过调节各权重值以达到最小。

**训练策略**:梯度下降法

$$\Delta w_{ij}=-\eta\frac{\partial E}{\partial w_{ij}}$$

### 二.单层前馈神经网络（单层感知器）

#### 1.网络描述

* 该网络由$d+1$个输入结点(包含一个 bais 结点)和一个含有$c$个结点的输出层构成，没有隐蔽层。
* 输入向量：$x=[1,x_1,x_2,x_3,...,x_d]^T$

* 输出向量：$z= [z_1,z_2,...z_c]^T$
* 权重集合：$\{w_{ij}\}$

* 对于输出节点$j$，其输入的加权和为：$$net_j=\Sigma_{i=0}^dw_{ij}x_i=w_j^Tx$$

* 对于输出结点$j$，其输出值$z_j$为：$$z_j=f(net_j)=f(\Sigma_{i=0}^dw_{ij}x_i)$$   （经过激励）

#### 2.感知器的训练

1. ##### 线性单元

   * 转移函数为线性函数：$$f(net)=net$$

   * 线性单元的训练：$\delta$规则

   * 误差函数：$$E(W)=\frac{1}{2}\Sigma_{j,k}(t_j^k-z_j^k)^2=\frac{1}{2}\Sigma_{k,j}(t_j^k-\Sigma w_{ij}x_i^k)^2$$

   * 

     







